---
title:   GCP VM Compute Engine
created: 2021-04-12
---

- Meta :  [[AI]]  [[GCP-Deployement]]
- Ce qui concerne l'installation d'une VM sur compute engine
- ------------------------------------------------
- Machine custom pour avoir pleins de RAM, sinon le fast ai donne des highmem cool
- pour mettre dans un microservice API :
	- https://github.com/RafaelWO/NLP-Microservice
- pour transférer des fichiers depuis une VM vers le disque
	- ```javascript
	- gcloud compute scp --recurse --compress gpuserver:/home/USERNAME/finetune-gpt2xl/finetuned/ . --ssh-key-file=./.ssh/jpkey
	- ```
- Creation
	- Script Fast AI avec moins de RAM
	  collapsed:: true
		- ```javascript
		- export IMAGE_FAMILY="pytorch-latest-gpu" # or "pytorch-latest-cpu" for non-GPU instances
		- export ZONE="us-central1-f"
		- export INSTANCE_NAME="my-fastai-instance"
		- export INSTANCE_TYPE="n1-highmem-8" # budget: "n1-highmem-4"
		-
		- # budget: 'type=nvidia-tesla-t4,count=1'
		- gcloud compute instances create $INSTANCE_NAME \
		- --zone=$ZONE \
		- --image-family=$IMAGE_FAMILY \
		- --image-project=deeplearning-platform-release \
		- --maintenance-policy=TERMINATE \
		- --accelerator="type=nvidia-tesla-p100,count=1" \
		- --machine-type=$INSTANCE_TYPE \
		- --boot-disk-size=200GB \
		- --metadata="install-nvidia-driver=True" \
		- --preemptible
		- ```
	- Script utilisé
		- ```shell
		- export VMZONE="europe-west3-b"
		-
		- gcloud compute instances create gpuserver \
		- --project $PROJECT_ID \
		- --zone $VMZONE \
		- --custom-cpu 12 \
		- --custom-memory 78 \
		- --maintenance-policy TERMINATE \
		- --image-family pytorch-1-7-cu110 \
		- --image-project deeplearning-platform-release \
		- --boot-disk-size 200GB \
		- --metadata "install-nvidia-driver=True" \
		- --accelerator="type=nvidia-tesla-t4,count=1" \
		- --preemptible
		-
		- gcloud compute ssh YOURSDKACCOUNT@gpuserver --zone=us-west1-b
		-
		-
		- ```
	- utilise tuto
		- https://github.com/Xirider/finetune-gpt2xl
		- vérifier https://docs.aitextgen.io/tutorials/generate_1_5b/
	- Process :
		- en gros on change le quota  en demandant du GPU
		- Pour GPU : T4 prendre Europe West 3 b. c'est genre 0.11 de l'heure.
			- T4
				- europe-west2-a
				- europe-west2-b
				- europe-west4-b
				- **europe-west4-c** car il a les 2
			- europe-west4-a / b ou C  V100
			-
		- ensuite
		- Attention au shutdown et restart https://console.cloud.google.com/compute/instance
- Output
	- ```shell
	- sudo /opt/deeplearning/install-driver.sh
	- Linux gpuserver 4.19.0-14-cloud-amd64 #1 SMP Debian 4.19.171-2 (2021-01-30) x86_64
	-
	- ```
- Connexion SSH
	- tout simple : gcloud compute ssh USERNAME@gpuserver --zone=$VMZONE va créer une clef temp
	- si besoin de plus de permanence
	- ```shell
	- export KEYNAME="jpkey"
	- export VMUSER="USERNAME"
	-
	- ssh-keygen -t rsa -f ~/.ssh/$KEYNAME -C $VMUSER
	- chmod 400  ~/.ssh/$KEYNAME
	-
	- aller ensuite sur https://cloud.google.com/compute/docs/instances/adding-removing-ssh-keys#console_1
	-
	- gcloud compute ssh USERNAME@gpuserver --zone=$VMZONE --ssh-key-file=./.ssh/jpkey
	- ```
- Tuto pour mettre VSCODE
	- https://towardsdatascience.com/unleash-the-power-of-visual-studio-code-vscode-on-google-cloud-platform-virtual-machine-f75f78f49aee
- auto pour travailler à distance
	- https://medium.com/@summitkwan/guide-work-remotely-on-a-linux-server-from-local-mac-windows-f05cdc6db0e0
	- https://cloud.google.com/solutions/chrome-desktop-remote-on-compute-engine?hl=fr
	-