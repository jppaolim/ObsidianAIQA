# Les expÃ©riences de pensÃ©e pour comprendre l'IA et ChatGPT ğŸ§ ğŸ¤–
![Les expÃ©riences de pensÃ©e pour comprendre l'IA et ChatGPT ğŸ§ ğŸ¤–](https://media.licdn.com/dms/image/D4E12AQHVsim6yRy4hA/article-cover_image-shrink_720_1280/0/1683063236782?e=2147483647&v=beta&t=NAYbEGTYpE6C7Ezl0F4-wDi9LpjoC7nENVP4aDD_OqY)

Elemental Creation #119 Charlesai

Jâ€™ai assistÃ© Ã  une confÃ©rence passionnante de Yann LeCun Ã  la New York University il y a 2 semaines. Je me suis rendu compte Ã  cette occasion que **les expÃ©riences de pensÃ©e et exemples citÃ©s** par les invitÃ©s de mon podcast **[Comptoir IA**](https://podcasters.spotify.com/pod/show/nicolas-guyon)** pour expliquer simplement lâ€™IA et ses enjeux** Ã©taient souvent les mÃªmes ğŸ™Œ

Les voici !

  * ğŸ¤–ğŸ‘¨ Le paradoxe de Moravec
  * ğŸ‡¨ğŸ‡³ La chambre Chinoise
  * ğŸ¦âœˆï¸ Lâ€™oiseau et lâ€™avion
  * ğŸšƒ Le dilemme du tramway
  * ğŸ¤–ğŸ’» Le test de Turing
  * ğŸ¤–âš–ï¸ Les lois des robots

* * *

ğŸ¤–ğŸ‘¨  **Le paradoxe de Moravec (1980)** : les tÃ¢ches qui sont faciles pour les humains, telles que la reconnaissance d'objets, la locomotion ou la manipulation d'objets, sont souvent difficiles Ã  rÃ©aliser pour les robots et les IA. Inversement, les tÃ¢ches qui sont complexes pour les humains, comme les calculs mathÃ©matiques avancÃ©s, sont souvent simples pour les machines.

ğŸ”¸ Moravec explique ce paradoxe en soulignant que les compÃ©tences humaines de base, comme la perception et la motricitÃ©, sont le rÃ©sultat de millions d'annÃ©es d'Ã©volution ğŸ¦– et sont donc complexes Ã  reproduire artificiellement, tandis que les compÃ©tences cognitives supÃ©rieures se sont dÃ©veloppÃ©es plus rÃ©cemment et sont plus facilement imitables.

ğŸ”¹ **Cela permet de comprendre les annÃ©es nÃ©cessaires au dÃ©veloppement des robots de **Boston Dynamics** par rapport Ã  lâ€™Ã©mergence des LLM comme **ChatGPT

![No alt text provided for this image](//:0)

* * *

ğŸ‡¨ğŸ‡³ **La chambre Chinoise** est une expÃ©rience de pensÃ©e proposÃ©e par le philosophe John Searle pour contester l'idÃ©e que l'intelligence artificielle puisse rÃ©ellement comprendre et possÃ©der la conscience. L'expÃ©rience consiste en une chambre dans laquelle une personne ne comprenant pas le chinois reÃ§oit des questions Ã©crites en chinois. En utilisant un ensemble de rÃ¨gles et de rÃ©fÃ©rences, cette personne est capable de rÃ©pondre correctement aux questions sans comprendre rÃ©ellement la langue. Searle soutient que, mÃªme si la chambre peut donner l'impression de comprendre le chinois, elle n'a pas la comprÃ©hension ou la conscience rÃ©elle du langage.

ğŸ”¸ Cette expÃ©rience de pensÃ©e vise Ã  montrer que les machines, mÃªme si elles peuvent simuler la comprÃ©hension humaine, ne possÃ¨dent pas rÃ©ellement la conscience ou l'intentionnalitÃ©.

**ğŸ”¹ ChatGPT est dans la simulationâ€¦ jusquâ€™Ã  quel point ?**

![No alt text provided for this image](//:0)

* * *

ğŸ¦âœˆï¸ **Lâ€™oiseau et lâ€™avion** : Yann LeCun a citÃ© lâ€™exemple de **l'avion "chauve-souris" **d'Ader conÃ§u en 1890. Le design de l'Ã‰ole Ã©tait inspirÃ© par la morphologie des chauves-souris, avec des ailes en forme de membrane soutenues par une structure en bois, il aurait effectuÃ© un court vol non contrÃ´lÃ© d'environ 50 mÃ¨tres Ã  une faible altitude.

ğŸ”¸ La recherche en IA doit sâ€™inspirer de la nature mais pas la copier, pour lâ€™avion, on sâ€™intÃ©resse Ã  certaines fonctionnalitÃ©s mais on ne cherche pas Ã  rÃ©inventer lâ€™oiseau, sinon les avions auraient aujourdâ€™hui des plumes !

**ğŸ”¹ Cet exemple permet de comprendre le dÃ©veloppement de la recherche sur le deep learning et les LLM**

![No alt text provided for this image](//:0)

* * *

ğŸšƒ **Le dilemme du tramway** est une expÃ©rience de pensÃ©e Ã©thique qui met en scÃ¨ne un scÃ©nario hypothÃ©tique oÃ¹ un tramway est sur le point de causer un accident mortel. Vous Ãªtes devant un levier qui peut changer la direction du tramway. Si vous ne faites rien, le tramway tuera cinq personnes sur la voie actuelle. Si vous tirez le levier, le tramway changera de voie et tuera une personne.

ğŸ”¸ Le dilemme soulÃ¨ve des questions Ã©thiques complexes, telles que la responsabilitÃ©, l'action versus l'inaction et la moralitÃ© de sacrifier une vie pour en sauver plusieurs.

**ğŸ”¹ Le problÃ¨me se pose notamment avec lâ€™arrivÃ©e des voitures autonomes et des robots intelligents, et les dÃ©cisions sont dorÃ©navant inscrites dans le code source !**

![No alt text provided for this image](//:0)

* * *

ğŸ¤–ğŸ’» **Le test de Turing**, proposÃ© par le mathÃ©maticien et informaticien britannique Alan Turing en 1950, est une expÃ©rience de pensÃ©e visant Ã  dÃ©terminer si une machine peut afficher un niveau d'intelligence comparable Ã  celui d'un humain. Le test implique une sÃ©rie de conversations entre un humain, un ordinateur et un juge humain. Le juge interagit avec l'humain et l'ordinateur par le biais de messages textuels, sans savoir lequel est la machine et lequel est l'humain.

ğŸ”¸ Si le juge ne peut pas distinguer avec succÃ¨s l'ordinateur de l'humain sur la base de leurs rÃ©ponses, la machine est considÃ©rÃ©e comme ayant rÃ©ussi le test de Turing et est jugÃ©e capable de montrer un comportement intelligent.

**ğŸ”¹ Le test de Turing semble passÃ© avec succÃ¨s par ChatGPT mais pose des questions sur la nature de lâ€™intelligence**

![No alt text provided for this image](//:0)

* * *

ğŸ¤–âš–ï¸ **Les lois des robots**, Ã©galement connues sous le nom des Trois lois de la robotique, sont un ensemble de rÃ¨gles Ã©thiques pour les robots imaginÃ©es par l'Ã©crivain de science-fiction Isaac Asimov (1942).

  1. Un robot ne peut pas porter atteinte Ã  un Ãªtre humain ni, par son inaction, permettre qu'un Ãªtre humain soit exposÃ© au danger.
  2. Un robot doit obÃ©ir aux ordres donnÃ©s par les Ãªtres humains, sauf si ces ordres entrent en conflit avec la premiÃ¨re loi.
  3. Un robot doit protÃ©ger son existence tant que cette protection n'entre pas en conflit avec la premiÃ¨re ou la deuxiÃ¨me loi.

ğŸ”¸ Il va devenir urgent de considÃ©rer lâ€™IA comme notre enfant, de lui donner une civilitÃ©, des droits et des devoirs

**ğŸ”¹ Cela fait penser Ã  lâ€™entraÃ®nement dâ€™**Anthropic**, rival dâ€™**OpenAI** AI sur une Constitution !**

![No alt text provided for this image](//:0)

* * *

â€œToute technologie suffisamment avancÃ©e nâ€™a rien Ã  envier Ã  la magie !â€ Arthur C. Clarke

* * *

Yann LeCun / Yann Lechelle / Nils Schaetti / laurent alexandre / Vincent Pinte Deregnaucourt / Paul Mouginot / Jean-Louis QuÃ©guiner / Benjamin Trom, PhD / Dr. Jennifer Prendki / Thomas Solignac / Stanislas Polu / Stephane MALLARD / Olivier Martinez / Guillaume Avrin / Charles-Edouard BouÃ©e / Karim Beguir / werber bernard / Luc Ferry / Michel Levy ProvenÃ§al / CÃ©dric Villani / Loic Le Meur / Laodis Menard / Brivael Le Pogam / Martin Pavanello / Pierre Entremont
