author:: Nina Schick
source:: ['We have no moat, and neither does Open AI'](https://ninaschick.substack.com/p/we-have-no-moat-and-neither-does)
clipped:: [[2023-05-07]]
published:: 

#clippings

This is the headline of a leaked internal document from a Google researcher that has gone viral overnight. It argues that neither Big Tech incumbents nor GenAI upstarts are positioned to win the AI arms race.

A third player - the open-source AI community - has been making rapid progress, outpacing both Google and OpenAI in AI innovation and accessibility.

> We’ve done a lot of looking over our shoulders at OpenAI. Who will cross the next milestone? What will the next move be? But the uncomfortable truth is, *we aren’t positioned to win this arms race and neither is OpenAI*. While we’ve been squabbling, a third faction has been quietly eating our lunch. I’m talking, of course, about open source. Plainly put, they are lapping us.
> 
> (H/T to [Dylan Patel at SemiAnalysis](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither) for breaking the story.)

The memo cites several recent developments, including the open-source releases of **Stable Diffusion** (the foundational text-to-image model) and **LLaMA** (Meta's foundational large language model), as well as **LoRA** (low-rank adaptation). This technique fine-tunes AI models more efficiently, allowing for customization on everyday devices like laptops using high-quality, smaller datasets instead of huge datasets.

The memo argues that, ultimately, Google and OpenAI need the open-source community more than the other way around. Google should establish itself as an open-source community leader — even if it means relinquishing control.

Last year, [I identified the open vs closed race](https://ninaschick.substack.com/p/10-predictions-for-generative-ai) towards GenAI as a defining trend for this space. In my conversation with [Emad Mostaque](https://ninaschick.substack.com/p/1-emad-mostaque-generative-ai-as), we spoke about the open-source release of Stable Diffusion in August 2022 as a watershed moment.

While Open AI's DALLE 2 came out months before, its impact was limited due to its restricted nature. By comparison, the release of Stable Diffusion was like a bomb going off, setting in motion the debate about 'AI-art' and, more generally, on how to interpret AI-generated outputs.

![#1 - Emad Mostaque: Generative AI as a public good](https://substackcdn.com/image/youtube/w_728,c_limit/aNYPCQBqnTY)

Hello GenAI’ers, Today I bring you my conversation with Emad Mostaque, the CEO and Founder of Stability AI. Emad and Stability are integral to the story of Generative AI. The open release of Stable Diffusion in August 2022 was a watershed moment, but that doesn’t even scratch the surface of what’s coming next.

I have no doubt that Stable Diffusion was a wake-up call to Open AI. It realised that it could not afford to rest on its laurels. This resulted, in my view, in the release of ChatGPT only two months after Stable Diffusion. While OpenAI's large language models (LLMs) are not open source, ChatGPT was designed for impact and adoption. The rest, of course, is history.

Some Big Tech players already ‘get’ that they need to collaborate with the open-source community. Apple was the first, introducing optimizations that allowed Stable Diffusion to run faster on Apple devices. Since then AWS has partnered with Hugging Face, and the open-source release of LLaMA by Meta has become the ‘Stable Diffusion moment’ for large language models.

As these collaborations prove, the private vs open-source dynamic is not necessarily a zero-sum game, and Big Tech may have much more to gain by working with, rather than against, the open-source community

Still, a collaborative future is not inevitable. Political tensions about control and accessibility may prevent it. As the debate around AI safety and ethics heats up (and we ain’t seen anything yet) — I am sure that there will be *a lot* of lobbying to ensure that the open-source community gets extra scrutiny from regulators.

Right now, it’s the private companies who are in the spotlight. Just this week, US President Joe Biden made a personal intervention, warning of AI’s ‘extraordinary potential and dangers,’ at a meeting of all the Big Tech chiefs at the White House. Meanwhile, in the UK, the Competitions and Markets Authority (CMA) announced a review into foundational models — literally days after the British government launched an AI taskforce to fund them. (FYI, The CMA is the body that just blocked Microsoft’s $68.7 billion acquisition of gaming platform Activision — so it has bite.)

So when the screws are tightened, who will throw whom under the bus?

Will Big Tech be checked … or will open-source become one of the first victims of ‘safe’ AI?

Only time will tell. (If you want to get deeper into this — check out my conversations on decentralized AI with [Emad Mostaque](https://ninaschick.substack.com/p/1-emad-mostaque-generative-ai-as); [Thomas Wolf](https://ninaschick.substack.com/p/pioneer-ai-for-everyone-thomas-wolf), and Christoph Schuhmann.)

And, now, on to the best of the rest….

**‘Godfather of AI’ Quits Google, warning of AI’s Existential Risks**

-   Headlines have been dominated by Geoffrey Hinton quitting his part-time role at Google, and warning about the existential risks of AI.
    
-   Hinton joins a growing chorus of experts concerned about AI’s seismic impacts on society.
    
-   Although Hinton’s message is not particularly novel — the rolling coverage of his intervention suggests that the narrative of the approaching singularity, or of ‘AI obliteration,’ is irresistible.
    

**Biden Administration announces new measures for ‘Responsible AI Innovation’**

-   Following a meeting of the AI bigwigs at the White House to discuss AI's ‘safe’ development (including the CEOs of Open AI, Google and Microsoft), the Biden administration announced new measures to promote ‘responsible AI innovation’ to ‘protect Americans' rights and safety.’
    
-   The measures include establishing a National AI Advisory Committee to provide recommendations on AI-related issues and the development of ethical principles for federal agencies that use AI.
    

**Grimes launches AI Software to allow fans to replicate her vocals**

-   Rather than suing anyone who uses her voice, the artist Grimes has launched an AI software - ELFTECH - to help people do it. What’s in it for her? A 50/50 royalty split.
    
-   Whilst most artists are trying to stop this from happening, she’s figuring out how this can work for her and her fans — not least because it’s a potential huge avenue for her to monetise her brand.
    
-   Huge disruption ahead for the music and entertainment industry. As Napster led to the streaming revolution, a new business model incorporating AI-led creation and collaboration is next.
    

**Hackers using ChatGPT-lures to spread Malware on Facebook**

-   The AI-powered disinformation and hacker hell is already here… Meta reports that ChatGPT-lures to convince Facebook users to download malicious software are on the rise.
    
-   These malware campaigns use automated messages to engage with potential victims, using the chatbot to impersonate a friendly contact to encourage them to click on a link. (Ugh, this type of thing will only get uglier from hereon in.)
    

-   Hugging Face and ServiceNow have developed an open-source code-generating model called Code-Model.
    
-   The model is based on GPT-3 and is designed to help developers generate high-quality code from natural language queries, saving time and reducing errors.
    
-   Code-Model has been tested by ServiceNow developers and is available for free on the Hugging Face Model Hub.
    

Pi – the new Chatbot on the block

-   There’s a new chatbot on the block — PI. It’s the brainchild of Reid Hoffman and Mustafa Suleyman (formerly of DeepMind) and their new GenAI venture: Inflection AI. Inflection has raised $225m in funding so far, and aims to raise up to $675m more.
    
-   PI hopes to stand out in the saturated chatbot market, as “a kind and supportive companion” offering conversations, friendly advice, and concise information in a natural, flowing style.
    
-   Are you creeped out by an AI assistant constantly gathering your personal data to become optimised for you — or is it exactly what you need?
    

See you next Friday!

Namaste,

Nina