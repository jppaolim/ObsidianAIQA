# 10 Minutes to Deploying a Deep Learning Model on Google Cloud Platform
- Meta :  [[Framework VFA pr tweet interessant]]   [[GCP-Deployement]]
- URL :  https://towardsdatascience.com/10-minutes-to-deploying-a-deep-learning-model-on-google-cloud-platform-13fa56a266ee
- Date read : [[2021-03-23]]
- Author : 
- Summary & learning : permettre de deployer une machine Compute, avec du swap 

- ------------------------------------------------ 

- ## How to deploy a Deep Learning model to GCP, entirely for free, forever
    - [![Binh Phan](https://miro.medium.com/fit/c/56/56/2*tUP5xJE75yEm_bY31klAEQ.jpeg)](https://medium.com/@btphan95?source=post_page-----13fa56a266ee--------------------------------)
    - [Binh Phan](https://medium.com/@btphan95?source=post_page-----13fa56a266ee--------------------------------)
    - [Jun 20, 2020Â·5 min read](https://towardsdatascience.com/10-minutes-to-deploying-a-deep-learning-model-on-google-cloud-platform-13fa56a266ee?source=post_page-----13fa56a266ee--------------------------------)
    - ![](https://miro.medium.com/max/60/1*iLM7XiIsqbvuoxCTeWA4dQ.jpeg?q=20)
    - ![](https://miro.medium.com/max/640/1*iLM7XiIsqbvuoxCTeWA4dQ.jpeg)deploy a dandelion and grass image classifier onto the web, through Google Cloud Platform! Source:Â [Pixabay](https://pixabay.com/photos/dandelion-sky-flower-nature-seeds-463928/)
    - So youâ€™ve trained a Machine Learning model that youâ€™re ecstatic about, and now, you want to share itÂ with the world. And so you built a web app to serve the model, only to find out that you donâ€™t know how to host this web app on the Internet 24/7.Â __After all, if no one can see your ML model in production, does it really exist?__Â This tutorial came out of the need to share an easy andÂ **free**Â way to deploy a deep learning model to production onÂ [Google Cloud Platform using itsÂ __always-free__Â compute service](https://cloud.google.com/free), the f1-micro. As an example, weâ€™ll be deploying a dandelion and grass classifier built using theÂ [FastAI deep learning library](https://github.com/fastai/fastai). I hope that you will be able to deploy your trained model to the world in under 30 minutes, seamlessly and effortlessly.
    - **Requirements**: You will need just the computer you have now, and a Google account!
    - This tutorial will be broken down into 4 steps:
        - Sign in to Google Cloud and create an f1-micro instance on Compute Engine
        - Pull the trained model from Github
        - Add swap memory
        - Serve model onto the web with Starlette
        - Build the web app in a Docker container
        - Run Docker container
- # 1. Sign in to Google Cloud and Create a f1-micro Instance
    - ![](https://miro.medium.com/max/60/1*Xc1DvIz4TQqX9QouYe5OWg.png?q=20)
    - ![](https://miro.medium.com/max/515/1*Xc1DvIz4TQqX9QouYe5OWg.png)Signing up for Google Cloud Platform is free
    - If you havenâ€™t already, sign up for Google Cloud Platform through your Google account. Youâ€™ll have to enter your credit card, but you wonâ€™t be charged anything upon signing up. Youâ€™ll also get $300 worth of free credits that last for 12 months! Youâ€™ll be utilizing GCPâ€™s free tier, so you wonâ€™t have to pay to follow this tutorial.
    - Once youâ€™re in the console, go to Compute Engine and create an instance. Youâ€™ll need to:
        - name the instanceÂ greenr
        - set the compute instance asÂ f1-micro
        - set the OS to Ubuntu 16.04
        - ramp up the HDD memory to 25GB
        - Allow cloud access to APIs and HTTP/HTTPS traffic
    - how to create a VM instance
    - When your instance has been created and is running, SSH into your instance by clicking on the SSH button located on the right side of the screen.
- # 2. Pull the Trained Model from Github
    - First, letâ€™s grab the exported model that we already trained on from Github. If youâ€™re interested in learning how to train a dandelion and grass image classifier using FastAI,Â [follow this notebook hosted on Kaggle](https://www.kaggle.com/btphan/greenr-an-image-classifier-in-fastai?scriptVersionId=33945487)! I recommend using the library and following the FastAI course if youâ€™re interested in deep learning.
    - Clone this repository from theÂ [greenr repo on Github](https://github.com/btphan95/greenr)Â containing the exported model,Â export.pkl:
    - git clone https://github.com/btphan95/greenr-tutorial
- # 3. Add Swap Memory to Our Compute Instance
    - This is where it gets a bit hacky. OurÂ f1-microÂ instance only supports up toÂ __0.6GB__Â of RAM, meaning itâ€™s ultra-weak and not capable of installing all of our required deep learning libraries, which are upwards of 750MB in size. Weâ€™re going to add swap memory to our little friend to utilize its existing HDD space as RAM to make this all work. Fortunately, I put all of this part into a script, so just runÂ swap.shfrom our greenr repo to add 4GB of swap memory to our machine:
    - cd greenr-tutorial
    - sudo bash swap.sh
    - Note that if youâ€™re using a stronger VM instance, then you wonâ€™t have to follow this step
- # 4. Serve Model onto the Web with Starlette
    - Now, weâ€™re going to build a Python script that will serve our model for inference on the web using the Starlette ASGI web framework. Why Starlette and not Flask? Both are web frameworks written in Python, butÂ [Starlette, along with Uvicorn, isÂ __way__Â faster than Flask and more scalable in production](https://www.techempower.com/benchmarks/[[section]]=data-r17&hw=ph&test=fortune&l=zijzen-1).
    - Using your favorite text editor, copy the following code to a python script called app.py in the greenr-tutorial directory.
    - This will create a Starlette server on port 8008 with a web page where a user can upload an image and get results (is it a dandelion or grass?)
    - Before moving on, weâ€™re also going to add a file calledÂ requirements.txt, which will allow Docker to install all of our required libraries when building a container. Vim and copy the following text intorequirements.txtÂ in the greenr-tutorial folder:
- # 5. Containerize App Using Docker
    - Using Docker lets us build compact containerized environments with only the libraries and data that we need.
    - First, weâ€™re going to use Docker to build a container where our app will live. This lets us run the app in its own environment, anywhere.
    - First,Â [install Docker](https://docs.docker.com/engine/install/ubuntu/):
    - uninstall old versions:
    - sudo apt-get remove docker docker-engine docker.io containerd runc
    - set up the repository:
    - ```javascript
    - - sudo apt-get update
    - - sudo apt-get install \
    - -     apt-transport-https \
    - -     ca-certificates \
    - -     curl \
    - -     gnupg-agent \
    - -     software-properties-common
    - 
    - ```

    - add Dockerâ€™s official GPG key:
    - curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
    - add the stable repository:
    - sudo add-apt-repository \
    -    "deb [arch=amd64] https://download.docker.com/linux/ubuntu \
    -    $(lsb_release -cs) \
    -    stable"
    - install Docker engine:
    - sudo apt-get update
    - sudo apt-get install docker-ce docker-ce-cli containerd.io
    - verify installation by running the hello-world image (it should print an informational message verifying that installation was a success):
    - sudo docker run hello-world
    - Now, in the greenr-tutorial directory, youâ€™ll need to create a Dockerfile that gives Docker instructions to build a container. First, vim intoDockerfileand add the following lines:
    - This Dockerfile will install the required libraries in a Python3.6 environment, add the necessary files to the container, and run the Starlette server in app.py.
    - In the greenr directory, build the Docker container with the following command:
    - sudo docker image build -t app:latest .
- # 6. Run Docker Container
    - Now, all we have to do is run our Docker container!
    - sudo docker run -d -p 80:8008 app:latest
    - Now, letâ€™s visit the External IP address of our machine, which you can find on Compute Engine. Make sure when you enter it in your browser, to format it like this (for my instance):Â http://34.68.160.231/
    - ![](https://miro.medium.com/max/50/1*Pyij17XF6T5CPB2tykbi_g.png?q=20)
    - ![](https://miro.medium.com/max/482/1*Pyij17XF6T5CPB2tykbi_g.png)the final deployed model on the web!
    - ![](https://miro.medium.com/max/60/1*FUMt6eC-8kOsbs0fSf6NIg.png?q=20)
    - ![](https://miro.medium.com/max/723/1*FUMt6eC-8kOsbs0fSf6NIg.png)the final result!
    - If you see the above, then you made it to the end. Congrats!ðŸŽ‰ Now, you can keep running your machine forever, because it is part of Googleâ€™s always-free tier.