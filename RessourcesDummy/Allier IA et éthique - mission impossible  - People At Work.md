**En novembre dernier, Positive AI a été lancée pour insuffler une IA responsable dans les organisations. Présentation de cette initiative unique avec Lætitia Orsini Sharps, directrice grand public d’Orange France et présidente de l’association.**

_ _

_« Nous nous sommes rendu compte que les entreprises avaient aujourd’hui besoin d’accompagnement et de solutions pour progresser et rendre visible la mise en œuvre d’une IA responsable au sein de leur organisation »,_ déclare Lætitia Orsini Sharps, directrice grand public d’Orange France et présidente de Positive AI, une association créée en 2022 par Orange France, L’Oréal, Malakoff Humanis et BCG Gamma. _« L’IA responsable, c’est pour le bénéfice de l’humain et c’est contrôlé par l’humain »,_ poursuit-elle. _Il est extrêmement important que les entreprises soient capables de montrer que ce progrès technologique est bien au service de la société. »_

L’une des principales missions de Positive AI est _« d’offrir aux entreprises un espace d’échange, de dialogue et de partage sur les bonnes pratiques pour réfléchir ensemble aux interrogations qui sont essentielles et faire progresser ce sujet d’une IA éthique et responsable »,_ précise sa présidente. Lætitia Orsini Sharps lance aussi un appel aux dirigeants pour qu’ils s’intéressent à ces problématiques, qui ne devraient pas, selon elle, concerner les seuls data scientists : _« Ce sont des sujets dont les dirigeants doivent s’emparer. Ils doivent comprendre tout le potentiel de cette IA, et en même temps toutes les règles et la gouvernance qu’il faut mettre en place pour que ces outils restent pilotés par l’humain et soient au service de l’humain. Des positions doivent être prises et elles doivent être très fortes. »_

**Un label certifiant la gouvernance et les systèmes d’une IA éthique**

Pour apporter des solutions concrètes permettant aux organisations de rendre opérationnelles ces bonnes pratiques, Positive AI est en train de finaliser la mise en place du premier label d’IA éthique en France. _« Ce label permettra aux entreprises de vérifier leur niveau de maturité sur l’IA responsable », _explique la dirigeante. À travers un référentiel établi par les équipes de data scientists et de chefs de projet des quatre entreprises fondatrices de l’association, et suivant les principales recommandations émises par la Commission européenne, ce label sera construit autour de deux piliers : la gouvernance de l’organisation et les systèmes d’IA eux-mêmes.

Une partie de ces systèmes, _« ceux qui seront identifiés comme présentant le plus de risques »,_ seront examinés en profondeur par les auditeurs. Les organisations devront aussi fournir des éléments prouvant leurs bonnes pratiques en matière de contrôle par l’humain de ces systèmes, par exemple, la protection de certaines populations. _« En auditant aussi la gouvernance, on peut revenir sur ce qui a été audité. Cela va garantir qu’au sein de l’entreprise on ait un système global vertueux. »_

La note finale donnant droit à la labellisation Positive AI, valable deux ans, permettra à l’organisation de savoir auquel des trois niveaux prévus par le référentiel correspond la maturité de son IA. Ce point est très important, selon la présidente, puisque le label doit être _« accessible à l’ensemble des entreprises »_ : _« On est vraiment dans une logique de progression et d’apprentissage en commun. »_ Les organisations fondatrices de l’association seront les premières à passer l’épreuve de la certification, et le label sera ensuite ouvert aux entreprises extérieures dans le courant du deuxième trimestre 2023.

**Mobiliser en interne et contribuer au débat public**

Ainsi, les organisations de toute taille et de tout secteur pourront adhérer à Positive AI et candidater au label. _« On a posé ce socle, mais il est au service de l’ensemble des entreprises, donc, plus nous serons nombreux, plus ce sera riche. C’est l’abondance de regards croisés, d’approches différentes, avec diverses modalités de mise en œuvre, qui fera la richesse de la démarche »,_ indique Lætitia Orsini Sharps. En interne, une IA responsable est également importante _« pour attirer et retenir les collaborateurs,_ poursuit-elle. _Les data experts cherchent du sens dans ce qu’ils font, dans leur parcours professionnel, et veulent s’impliquer dans des organisations qui partagent leurs préoccupations en matière d’éthique »._

Une autre ambition de Positive AI est de participer activement aux discussions sur la constitution de normes, tant au niveau français qu’à l’échelle européenne : _« Notre objectif est aussi de contribuer au débat public sur la régulation et les perspectives de l’IA, en se rapprochant d’acteurs publics et privés, en France et à l’étranger, pour mettre en commun cette approche. Cela nous semble important d’avoir une vision européenne de cette IA responsable. Nous contribuerons au débat en soutenant la position concrète et pragmatique d’entreprises qui font l’IA et qui l’utilisent. »_


<hr class="__chatgpt_plugin">

role::assistant

Positive AI, an association created by Orange France, L’Oréal, Malakoff Humanis, and BCG Gamma, is finalizing the implementation of the first ethical AI label in France. The label will allow companies to verify their level of maturity in responsible AI through a reference framework established by data scientists and project managers from the four founding companies. The label will be built around two pillars: the organization's governance and the AI systems themselves. The final score will determine the maturity level of the company's AI, and the label will be valid for two years. Positive AI's other goal is to contribute to the public debate on AI regulation and perspectives by supporting the pragmatic position of companies that use AI.

<hr class="__chatgpt_plugin">

role::user

can you tell me the drawbacks of such an approach ?



<hr class="__chatgpt_plugin">

role::assistant

While the Positive AI initiative has many benefits, there are also potential drawbacks to consider. 

One potential drawback is that the label may not be comprehensive enough to cover all aspects of ethical AI. While the reference framework is based on the recommendations of the European Commission, there may be other ethical considerations that are not included in the label.

Another potential drawback is that the label may not be accessible to all organizations. While the president of Positive AI states that the label is intended to be accessible to all companies, there may be smaller organizations that do not have the resources to undergo the certification process.

Finally, some critics may argue that the label is too focused on self-regulation and may not be sufficient to ensure that companies are truly implementing ethical AI practices. Some may argue that government regulation is necessary to ensure that companies are held accountable for their AI practices.

<hr class="__chatgpt_plugin">

role::user

